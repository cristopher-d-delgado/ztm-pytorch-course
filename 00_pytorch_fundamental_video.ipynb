{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27704000",
   "metadata": {},
   "source": [
    "# Pytorch Fundamentals \n",
    "\n",
    "Resource Notebook: https://www.learnpytorch.io/00_pytorch_fundamentals/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07807466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7748, -0.5168, -1.3999],\n",
      "        [-2.4638, -0.5399,  2.7552],\n",
      "        [ 1.4828, -0.2194, -0.1427]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import torchinfo, torchmetrics\n",
    "\n",
    "# Check PyTorch access (should print out a tensor)\n",
    "print(torch.randn(3, 3))\n",
    "\n",
    "# Check for GPU (should return True)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12a06f",
   "metadata": {},
   "source": [
    "## Introduction to Tensors \n",
    "\n",
    "### Creating Tensors\n",
    "Pytorch Tensors are created using `torch.Tensor()` = https://docs.pytorch.org/docs/stable/tensors.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83c0e8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "# Scalar Tensor \n",
    "scalar = torch.tensor(7)\n",
    "print(scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0c68ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# You can check the dimensions of the tensor using .ndim\n",
    "print(scalar.ndim)  # Output: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5701285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# You can turn a torch.Tensor to a Python integer using .item()\n",
    "print(scalar.item())  # Output: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5749393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 7])\n",
      "1\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Vector: \n",
    "# A vector is a single dimension tensor but can contain many numbers. \n",
    "# A vector has a magnitude and direction.\n",
    "vector = torch.tensor([7, 7])\n",
    "print(vector)\n",
    "print(vector.ndim)  # Output: 1\n",
    "print(vector.shape)  # Output: torch.Size([2])\n",
    "\n",
    "# You can tell the number of dimensions a tensor in PyTorch has by the number of square brackets on the outside ([) and you only need to count one side.\n",
    "# How many square brackets does vector have?\n",
    "# Another important concept for tensors is their shape attribute. The shape tells you how the elements inside them are arranged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "118ce1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "MATRIX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c49c994b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Check number of dimensions\n",
    "print(MATRIX.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "313406ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8435ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the output torch.Size([2, 2]) because MATRIX is two elements deep and two elements wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8616622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets create a Tensor \n",
    "# Tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "TENSOR\n",
    "\n",
    "# Tensors can represent almost anything.\n",
    "# The one we just created could be the sales numbers for a steak and almond butter store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07ac9703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Check number of dimensions for TENSOR\n",
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c84ef30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [3, 6, 9],\n",
      "        [2, 4, 5]])\n",
      "tensor([1, 2, 3])\n",
      "tensor([3, 6, 9])\n",
      "tensor([2, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Check shape of TENSOR\n",
    "print(TENSOR.shape)\n",
    "print(TENSOR[0])\n",
    "print(TENSOR[0][0])\n",
    "print(TENSOR[0][1])\n",
    "print(TENSOR[0][2])\n",
    "# That means there's 1 dimension of 3 by 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dad56d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]],\n",
    "\n",
    "                        [[4, 5, 6], \n",
    "                         [7, 8, 9], \n",
    "                         [1, 2, 3]]\n",
    "                         \n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff3ee91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n",
      "tensor([[4, 5, 6],\n",
      "        [7, 8, 9],\n",
      "        [1, 2, 3]])\n",
      "tensor([4, 5, 6])\n",
      "tensor([7, 8, 9])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Check shape of TENSOR\n",
    "print(TENSOR.shape)\n",
    "print(TENSOR[1])\n",
    "print(TENSOR[1][0])\n",
    "print(TENSOR[1][1])\n",
    "print(TENSOR[1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855717a1",
   "metadata": {},
   "source": [
    "### Random Tensors \n",
    "\n",
    "Why random Tensors?\n",
    "\n",
    "Random tensors are important b/c the way many neural networks learn is that tehy start with tensors full of random numbers and then adjust those random numbers to better represent the data. \n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05d40da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6651, 0.2227, 0.9717, 0.3999],\n",
       "         [0.1127, 0.9083, 0.5108, 0.2241],\n",
       "         [0.3607, 0.1284, 0.5809, 0.7187]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random Tensor with Pytorch \n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc07347",
   "metadata": {},
   "source": [
    "The flexibility of `torch.rand()` is that we can adjust the size to be whatever we want.\n",
    "\n",
    "For example, say you wanted a random tensor in the common image shape of `[224, 224, 3] ([height, width, color_channels])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "208d48ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (224, 224, 3)\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3)) \n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "573930ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6030, 0.8154, 0.2554],\n",
      "         [0.2987, 0.1891, 0.6887],\n",
      "         [0.5382, 0.3229, 0.7312],\n",
      "         ...,\n",
      "         [0.1278, 0.1335, 0.1984],\n",
      "         [0.1539, 0.4050, 0.5984],\n",
      "         [0.3832, 0.8670, 0.0312]],\n",
      "\n",
      "        [[0.1104, 0.6819, 0.9621],\n",
      "         [0.3942, 0.3354, 0.2026],\n",
      "         [0.0967, 0.2266, 0.7178],\n",
      "         ...,\n",
      "         [0.1006, 0.8469, 0.5533],\n",
      "         [0.8946, 0.5926, 0.2442],\n",
      "         [0.9320, 0.3678, 0.0369]],\n",
      "\n",
      "        [[0.6442, 0.2126, 0.0981],\n",
      "         [0.9105, 0.7775, 0.3153],\n",
      "         [0.6815, 0.5610, 0.3578],\n",
      "         ...,\n",
      "         [0.5091, 0.3356, 0.0039],\n",
      "         [0.1951, 0.1764, 0.9946],\n",
      "         [0.7080, 0.5637, 0.8466]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2630, 0.8530, 0.0797],\n",
      "         [0.4158, 0.5062, 0.6933],\n",
      "         [0.8461, 0.2471, 0.7364],\n",
      "         ...,\n",
      "         [0.2102, 0.4250, 0.0178],\n",
      "         [0.2687, 0.2955, 0.5076],\n",
      "         [0.2992, 0.6050, 0.2143]],\n",
      "\n",
      "        [[0.1151, 0.6011, 0.5778],\n",
      "         [0.4756, 0.7117, 0.9041],\n",
      "         [0.3313, 0.9752, 0.3488],\n",
      "         ...,\n",
      "         [0.6135, 0.9593, 0.6904],\n",
      "         [0.2358, 0.7036, 0.5421],\n",
      "         [0.1636, 0.0030, 0.1304]],\n",
      "\n",
      "        [[0.4236, 0.5450, 0.4094],\n",
      "         [0.7917, 0.8402, 0.1868],\n",
      "         [0.3806, 0.8528, 0.1619],\n",
      "         ...,\n",
      "         [0.8620, 0.2149, 0.8967],\n",
      "         [0.5561, 0.3869, 0.4348],\n",
      "         [0.4872, 0.7911, 0.3145]]])\n"
     ]
    }
   ],
   "source": [
    "print(random_image_size_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91490f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 1000, 5]), 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tensor = torch.rand(size=(1000, 1000, 5))\n",
    "special_tensor.shape, special_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "300a30ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.7087e-01, 8.0633e-01, 6.0963e-02, 9.2888e-01, 6.3703e-01],\n",
      "         [3.7982e-01, 7.5345e-01, 7.8266e-01, 7.8880e-03, 1.2927e-02],\n",
      "         [2.1075e-01, 9.1612e-01, 7.8879e-01, 6.2943e-01, 8.2132e-01],\n",
      "         ...,\n",
      "         [7.1792e-01, 6.5301e-01, 1.3619e-01, 1.4099e-03, 5.1422e-01],\n",
      "         [5.6986e-01, 8.4100e-01, 7.7917e-01, 9.8880e-01, 7.0044e-01],\n",
      "         [4.0097e-01, 7.4385e-02, 8.3725e-02, 3.2270e-01, 5.5438e-01]],\n",
      "\n",
      "        [[3.0251e-01, 3.6743e-02, 2.2372e-01, 8.9400e-01, 4.3881e-01],\n",
      "         [6.3046e-01, 7.0096e-01, 4.6019e-01, 4.3670e-01, 5.9554e-01],\n",
      "         [2.2606e-01, 5.6167e-01, 8.4165e-01, 9.3054e-01, 9.7456e-01],\n",
      "         ...,\n",
      "         [2.9404e-01, 4.8478e-01, 4.6217e-01, 2.0944e-01, 5.4974e-01],\n",
      "         [5.3407e-01, 2.8707e-01, 3.5417e-01, 5.7001e-01, 5.0136e-01],\n",
      "         [9.8608e-02, 4.8585e-02, 3.2061e-01, 5.1302e-01, 8.2844e-03]],\n",
      "\n",
      "        [[1.9145e-01, 2.0214e-01, 3.9355e-01, 6.8240e-01, 9.5578e-02],\n",
      "         [4.7995e-01, 5.8063e-01, 9.3333e-01, 4.5707e-01, 2.7700e-01],\n",
      "         [4.7415e-01, 8.7739e-01, 9.1984e-01, 4.8306e-01, 6.8838e-01],\n",
      "         ...,\n",
      "         [8.8030e-01, 5.9601e-01, 3.3165e-01, 2.3842e-01, 6.4067e-01],\n",
      "         [4.4909e-01, 5.2148e-01, 1.6000e-01, 4.9551e-01, 5.4869e-01],\n",
      "         [8.3470e-01, 3.8148e-01, 6.8280e-01, 6.8698e-01, 5.5417e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.4639e-01, 8.4869e-01, 6.5776e-01, 8.5707e-01, 7.2840e-01],\n",
      "         [3.5400e-01, 2.3922e-01, 1.4518e-01, 1.1987e-01, 3.2687e-01],\n",
      "         [2.8913e-01, 7.3779e-02, 8.2473e-01, 2.4240e-02, 7.9902e-01],\n",
      "         ...,\n",
      "         [7.0886e-02, 2.3697e-01, 9.1658e-01, 5.2753e-01, 2.4885e-01],\n",
      "         [1.1941e-01, 6.9583e-01, 3.5639e-01, 2.6361e-01, 9.5029e-01],\n",
      "         [3.6209e-01, 9.3527e-02, 2.7171e-01, 3.7926e-01, 9.9681e-01]],\n",
      "\n",
      "        [[8.2257e-01, 5.7715e-01, 3.9670e-01, 7.1837e-01, 3.2722e-01],\n",
      "         [4.3397e-01, 3.6090e-01, 1.2612e-01, 3.2943e-01, 4.5730e-01],\n",
      "         [2.3182e-01, 3.3753e-01, 9.6385e-02, 6.6006e-01, 6.8569e-01],\n",
      "         ...,\n",
      "         [3.5081e-01, 4.6019e-01, 7.6356e-01, 5.9336e-01, 3.3068e-01],\n",
      "         [4.7890e-01, 2.4710e-01, 8.8885e-01, 6.8908e-01, 5.8632e-01],\n",
      "         [2.2928e-01, 4.0525e-01, 6.4076e-01, 6.3167e-01, 2.6636e-01]],\n",
      "\n",
      "        [[8.5980e-01, 6.6255e-01, 9.0531e-01, 3.2478e-01, 6.5187e-01],\n",
      "         [1.4472e-01, 9.4771e-04, 7.9159e-01, 4.4324e-01, 7.8603e-01],\n",
      "         [3.7914e-01, 6.4498e-01, 2.1518e-01, 3.9219e-01, 2.4353e-01],\n",
      "         ...,\n",
      "         [7.1501e-01, 2.6440e-01, 6.9092e-01, 2.2420e-01, 4.1338e-01],\n",
      "         [1.2211e-01, 4.9400e-01, 1.6430e-01, 5.3761e-01, 1.6422e-01],\n",
      "         [8.4791e-01, 7.2648e-01, 5.2821e-01, 8.9635e-01, 5.8703e-02]]])\n"
     ]
    }
   ],
   "source": [
    "print(special_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd165f58",
   "metadata": {},
   "source": [
    "### Zeroes and Ones \n",
    "\n",
    "Sometimes we may just want to fill tensors with zeroes and ones. This typically happens a lot with masking (like masking some of the values in one tensor with zeroes to let a model know not to learn them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10217164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f141b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5461e3bb",
   "metadata": {},
   "source": [
    "### Creating a range of Tensors and Tensors-like\n",
    "\n",
    "Sometimes you might want a range of numbers, such as 1 to 10 or 0 to 100. \n",
    "You can use `torch.arange(start, end, step)` to do so. \n",
    "\n",
    "Where: \n",
    "* start = start of range \n",
    "* end = end of range \n",
    "* step = how many steps in between each value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba574239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a range of values 0 to 10\n",
    "zero_to_ten = torch.arange(start=0, end=11, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a0db7f",
   "metadata": {},
   "source": [
    "Sometimes you might want a tensor of a certain type with the same shape as another tensor. For example, a tensor of all zeros with the same shape as a previous tensor. \n",
    "\n",
    "To do so you can use `torch.zeros_like(inpyt)` or `torch.ones_like(input)` which return a tensor filled with zeros or ones in the same shape as the input respectively. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1de33c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also create a tensor of zeros similar to another tensor\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten) # will have same shape\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a50f6924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11])\n",
      "torch.Size([11])\n"
     ]
    }
   ],
   "source": [
    "print(zero_to_ten.shape)\n",
    "print(ten_zeros.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4caca70",
   "metadata": {},
   "source": [
    "### Tensor Datatypes\n",
    "\n",
    "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch and Deep Learning:\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33545f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                                            # What datatype is the tensor (e.g. float32, float16, etc.)\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                                            # What device is the tensor on (e.g. CPU, GPU)\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "                                                    # Whether or not to track gradients with the tensor operations\n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fabd4c4",
   "metadata": {},
   "source": [
    "See the [PyTorch documentation for a list of all available tensor datatypes](https://pytorch.org/docs/stable/tensors.html#data-types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335759bf",
   "metadata": {},
   "source": [
    "### Getting information from Tensors\n",
    "\n",
    "Once you've created tensors (or someone else or a PyTorch module has created them for you), you might want to get some information from them.\n",
    "\n",
    "We've seen these before but three of the most common attributes you'll want to find out about tensors are:\n",
    "\n",
    "* shape - what shape is the tensor? (some operations require specific shape rules)\n",
    "* dtype - what datatype are the elements within the tensor stored in?\n",
    "* device - what device is the tensor stored on? (usually GPU or CPU)\n",
    "\n",
    "Let's create a random tensor and find out details about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d4ad3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3688, 0.7041, 0.5112, 0.6484],\n",
      "        [0.0047, 0.7930, 0.7765, 0.9333],\n",
      "        [0.6900, 0.3533, 0.0081, 0.0462]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Find out details about it\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ce8265",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (Tensor Operations)\n",
    "\n",
    "In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n",
    "\n",
    "A model learns by investigating those tensors and performing a series of operations (could be 1,000,000s+) on tensors to create a representation of the patterns in the input data.\n",
    "\n",
    "These operations are often a wonderful dance between:\n",
    "\n",
    "* Addition\n",
    "* Substraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix multiplication\n",
    "\n",
    "And that's it. Sure there are a few more here and there but these are the basic building blocks of neural networks.\n",
    "\n",
    "Stacking these building blocks in the right way, you can create the most sophisticated of neural networks (just like lego!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29ff322",
   "metadata": {},
   "source": [
    "#### Basic Operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6fa46c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of values and add a number to it\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73784c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply it by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72354d08",
   "metadata": {},
   "source": [
    "Notice how the tensor values above didn't end up being tensor([110, 120, 130]), this is because the values inside the tensor don't change unless they're reassigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bdf7afdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors don't change unless reassigned\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbd7d9e",
   "metadata": {},
   "source": [
    "Let's subtract a number and this time we'll reassign the tensor variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aab2a9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract and reassign\n",
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa71e02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add and reassign\n",
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247ecb9a",
   "metadata": {},
   "source": [
    "PyTorch also has a bunch of built-in functions like torch.mul() (short for multiplication) and torch.add() to perform basic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b83f28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also use torch functions\n",
    "torch.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0587a4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original tensor is still unchanged \n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ac0cea",
   "metadata": {},
   "source": [
    "However, it's more common to use the operator symbols like * instead of torch.mul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d712d858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
    "print(tensor, \"*\", tensor)\n",
    "print(\"Equals:\", tensor * tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291011a",
   "metadata": {},
   "source": [
    "#### Matrix Multiplication (is all you need)\n",
    "\n",
    "Two main ways of performing multiplication in neural networks and deep learning:\n",
    "1. Element-wise multiplication\n",
    "2. Matrix Multiplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0729e619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise matrix multiplication\n",
    "print(tensor, '*', tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "494868c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d364baaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also use the \"@\" symbol for matrix multiplication, though not recommended\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575b4dc",
   "metadata": {},
   "source": [
    "You can do matrix multiplication by hand but it's not recommended.\n",
    "\n",
    "The in-built `torch.matmul()` method is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3365df40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.22 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Matrix multiplication by hand \n",
    "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "  value += tensor[i] * tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "746e0e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85bdee0",
   "metadata": {},
   "source": [
    "### One of the most common errors in deep learning (shape errors)\n",
    "\n",
    "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most common errors you'll run into in deep learning is shape mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2385c014",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      3\u001b[0m                          [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      4\u001b[0m                          [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      7\u001b[0m                          [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m], \n\u001b[0;32m      8\u001b[0m                          [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (this will error)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B) # (this will error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecd4719",
   "metadata": {},
   "source": [
    "We can make matrix multiplication work between `tensor_A` and `tensor_B` by making their inner dimensions match.\n",
    "\n",
    "One of the ways to do this is with a transpose (switch the dimensions of a given tensor).\n",
    "\n",
    "You can perform transposes in PyTorch using either:\n",
    "* `torch.transpose(input, dim0, dim1)` - where input is the desired tensor to transpose and `dim0` and `dim1` are the dimensions to be swapped. \n",
    "* `tensor.T` - where tensor is the desired tensor to transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "253a0128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7., 10.],\n",
      "        [ 8., 11.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B\n",
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4497a182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B.T\n",
    "print(tensor_A)\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d9a1a12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "\n",
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b3d44",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum, etc (aggregation)\n",
    "\n",
    "Checkpoint: 2:48:32 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ztm-pytorch-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
