{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27704000",
   "metadata": {},
   "source": [
    "# Pytorch Fundamentals \n",
    "\n",
    "Resource Notebook: https://www.learnpytorch.io/00_pytorch_fundamentals/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07807466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7748, -0.5168, -1.3999],\n",
      "        [-2.4638, -0.5399,  2.7552],\n",
      "        [ 1.4828, -0.2194, -0.1427]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import torchinfo, torchmetrics\n",
    "\n",
    "# Check PyTorch access (should print out a tensor)\n",
    "print(torch.randn(3, 3))\n",
    "\n",
    "# Check for GPU (should return True)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12a06f",
   "metadata": {},
   "source": [
    "## Introduction to Tensors \n",
    "\n",
    "### Creating Tensors\n",
    "Pytorch Tensors are created using `torch.Tensor()` = https://docs.pytorch.org/docs/stable/tensors.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83c0e8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "# Scalar Tensor \n",
    "scalar = torch.tensor(7)\n",
    "print(scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0c68ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# You can check the dimensions of the tensor using .ndim\n",
    "print(scalar.ndim)  # Output: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5701285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# You can turn a torch.Tensor to a Python integer using .item()\n",
    "print(scalar.item())  # Output: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5749393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 7])\n",
      "1\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Vector: \n",
    "# A vector is a single dimension tensor but can contain many numbers. \n",
    "# A vector has a magnitude and direction.\n",
    "vector = torch.tensor([7, 7])\n",
    "print(vector)\n",
    "print(vector.ndim)  # Output: 1\n",
    "print(vector.shape)  # Output: torch.Size([2])\n",
    "\n",
    "# You can tell the number of dimensions a tensor in PyTorch has by the number of square brackets on the outside ([) and you only need to count one side.\n",
    "# How many square brackets does vector have?\n",
    "# Another important concept for tensors is their shape attribute. The shape tells you how the elements inside them are arranged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "118ce1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "MATRIX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c49c994b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Check number of dimensions\n",
    "print(MATRIX.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "313406ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8435ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the output torch.Size([2, 2]) because MATRIX is two elements deep and two elements wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8616622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets create a Tensor \n",
    "# Tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "TENSOR\n",
    "\n",
    "# Tensors can represent almost anything.\n",
    "# The one we just created could be the sales numbers for a steak and almond butter store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07ac9703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Check number of dimensions for TENSOR\n",
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c84ef30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [3, 6, 9],\n",
      "        [2, 4, 5]])\n",
      "tensor([1, 2, 3])\n",
      "tensor([3, 6, 9])\n",
      "tensor([2, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Check shape of TENSOR\n",
    "print(TENSOR.shape)\n",
    "print(TENSOR[0])\n",
    "print(TENSOR[0][0])\n",
    "print(TENSOR[0][1])\n",
    "print(TENSOR[0][2])\n",
    "# That means there's 1 dimension of 3 by 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dad56d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]],\n",
    "\n",
    "                        [[4, 5, 6], \n",
    "                         [7, 8, 9], \n",
    "                         [1, 2, 3]]\n",
    "                         \n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff3ee91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n",
      "tensor([[4, 5, 6],\n",
      "        [7, 8, 9],\n",
      "        [1, 2, 3]])\n",
      "tensor([4, 5, 6])\n",
      "tensor([7, 8, 9])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Check shape of TENSOR\n",
    "print(TENSOR.shape)\n",
    "print(TENSOR[1])\n",
    "print(TENSOR[1][0])\n",
    "print(TENSOR[1][1])\n",
    "print(TENSOR[1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855717a1",
   "metadata": {},
   "source": [
    "### Random Tensors \n",
    "\n",
    "Why random Tensors?\n",
    "\n",
    "Random tensors are important b/c the way many neural networks learn is that tehy start with tensors full of random numbers and then adjust those random numbers to better represent the data. \n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05d40da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6651, 0.2227, 0.9717, 0.3999],\n",
       "         [0.1127, 0.9083, 0.5108, 0.2241],\n",
       "         [0.3607, 0.1284, 0.5809, 0.7187]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random Tensor with Pytorch \n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc07347",
   "metadata": {},
   "source": [
    "The flexibility of `torch.rand()` is that we can adjust the size to be whatever we want.\n",
    "\n",
    "For example, say you wanted a random tensor in the common image shape of `[224, 224, 3] ([height, width, color_channels])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "208d48ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (224, 224, 3)\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3)) \n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "573930ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6030, 0.8154, 0.2554],\n",
      "         [0.2987, 0.1891, 0.6887],\n",
      "         [0.5382, 0.3229, 0.7312],\n",
      "         ...,\n",
      "         [0.1278, 0.1335, 0.1984],\n",
      "         [0.1539, 0.4050, 0.5984],\n",
      "         [0.3832, 0.8670, 0.0312]],\n",
      "\n",
      "        [[0.1104, 0.6819, 0.9621],\n",
      "         [0.3942, 0.3354, 0.2026],\n",
      "         [0.0967, 0.2266, 0.7178],\n",
      "         ...,\n",
      "         [0.1006, 0.8469, 0.5533],\n",
      "         [0.8946, 0.5926, 0.2442],\n",
      "         [0.9320, 0.3678, 0.0369]],\n",
      "\n",
      "        [[0.6442, 0.2126, 0.0981],\n",
      "         [0.9105, 0.7775, 0.3153],\n",
      "         [0.6815, 0.5610, 0.3578],\n",
      "         ...,\n",
      "         [0.5091, 0.3356, 0.0039],\n",
      "         [0.1951, 0.1764, 0.9946],\n",
      "         [0.7080, 0.5637, 0.8466]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2630, 0.8530, 0.0797],\n",
      "         [0.4158, 0.5062, 0.6933],\n",
      "         [0.8461, 0.2471, 0.7364],\n",
      "         ...,\n",
      "         [0.2102, 0.4250, 0.0178],\n",
      "         [0.2687, 0.2955, 0.5076],\n",
      "         [0.2992, 0.6050, 0.2143]],\n",
      "\n",
      "        [[0.1151, 0.6011, 0.5778],\n",
      "         [0.4756, 0.7117, 0.9041],\n",
      "         [0.3313, 0.9752, 0.3488],\n",
      "         ...,\n",
      "         [0.6135, 0.9593, 0.6904],\n",
      "         [0.2358, 0.7036, 0.5421],\n",
      "         [0.1636, 0.0030, 0.1304]],\n",
      "\n",
      "        [[0.4236, 0.5450, 0.4094],\n",
      "         [0.7917, 0.8402, 0.1868],\n",
      "         [0.3806, 0.8528, 0.1619],\n",
      "         ...,\n",
      "         [0.8620, 0.2149, 0.8967],\n",
      "         [0.5561, 0.3869, 0.4348],\n",
      "         [0.4872, 0.7911, 0.3145]]])\n"
     ]
    }
   ],
   "source": [
    "print(random_image_size_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91490f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 1000, 5]), 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tensor = torch.rand(size=(1000, 1000, 5))\n",
    "special_tensor.shape, special_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "300a30ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.7087e-01, 8.0633e-01, 6.0963e-02, 9.2888e-01, 6.3703e-01],\n",
      "         [3.7982e-01, 7.5345e-01, 7.8266e-01, 7.8880e-03, 1.2927e-02],\n",
      "         [2.1075e-01, 9.1612e-01, 7.8879e-01, 6.2943e-01, 8.2132e-01],\n",
      "         ...,\n",
      "         [7.1792e-01, 6.5301e-01, 1.3619e-01, 1.4099e-03, 5.1422e-01],\n",
      "         [5.6986e-01, 8.4100e-01, 7.7917e-01, 9.8880e-01, 7.0044e-01],\n",
      "         [4.0097e-01, 7.4385e-02, 8.3725e-02, 3.2270e-01, 5.5438e-01]],\n",
      "\n",
      "        [[3.0251e-01, 3.6743e-02, 2.2372e-01, 8.9400e-01, 4.3881e-01],\n",
      "         [6.3046e-01, 7.0096e-01, 4.6019e-01, 4.3670e-01, 5.9554e-01],\n",
      "         [2.2606e-01, 5.6167e-01, 8.4165e-01, 9.3054e-01, 9.7456e-01],\n",
      "         ...,\n",
      "         [2.9404e-01, 4.8478e-01, 4.6217e-01, 2.0944e-01, 5.4974e-01],\n",
      "         [5.3407e-01, 2.8707e-01, 3.5417e-01, 5.7001e-01, 5.0136e-01],\n",
      "         [9.8608e-02, 4.8585e-02, 3.2061e-01, 5.1302e-01, 8.2844e-03]],\n",
      "\n",
      "        [[1.9145e-01, 2.0214e-01, 3.9355e-01, 6.8240e-01, 9.5578e-02],\n",
      "         [4.7995e-01, 5.8063e-01, 9.3333e-01, 4.5707e-01, 2.7700e-01],\n",
      "         [4.7415e-01, 8.7739e-01, 9.1984e-01, 4.8306e-01, 6.8838e-01],\n",
      "         ...,\n",
      "         [8.8030e-01, 5.9601e-01, 3.3165e-01, 2.3842e-01, 6.4067e-01],\n",
      "         [4.4909e-01, 5.2148e-01, 1.6000e-01, 4.9551e-01, 5.4869e-01],\n",
      "         [8.3470e-01, 3.8148e-01, 6.8280e-01, 6.8698e-01, 5.5417e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.4639e-01, 8.4869e-01, 6.5776e-01, 8.5707e-01, 7.2840e-01],\n",
      "         [3.5400e-01, 2.3922e-01, 1.4518e-01, 1.1987e-01, 3.2687e-01],\n",
      "         [2.8913e-01, 7.3779e-02, 8.2473e-01, 2.4240e-02, 7.9902e-01],\n",
      "         ...,\n",
      "         [7.0886e-02, 2.3697e-01, 9.1658e-01, 5.2753e-01, 2.4885e-01],\n",
      "         [1.1941e-01, 6.9583e-01, 3.5639e-01, 2.6361e-01, 9.5029e-01],\n",
      "         [3.6209e-01, 9.3527e-02, 2.7171e-01, 3.7926e-01, 9.9681e-01]],\n",
      "\n",
      "        [[8.2257e-01, 5.7715e-01, 3.9670e-01, 7.1837e-01, 3.2722e-01],\n",
      "         [4.3397e-01, 3.6090e-01, 1.2612e-01, 3.2943e-01, 4.5730e-01],\n",
      "         [2.3182e-01, 3.3753e-01, 9.6385e-02, 6.6006e-01, 6.8569e-01],\n",
      "         ...,\n",
      "         [3.5081e-01, 4.6019e-01, 7.6356e-01, 5.9336e-01, 3.3068e-01],\n",
      "         [4.7890e-01, 2.4710e-01, 8.8885e-01, 6.8908e-01, 5.8632e-01],\n",
      "         [2.2928e-01, 4.0525e-01, 6.4076e-01, 6.3167e-01, 2.6636e-01]],\n",
      "\n",
      "        [[8.5980e-01, 6.6255e-01, 9.0531e-01, 3.2478e-01, 6.5187e-01],\n",
      "         [1.4472e-01, 9.4771e-04, 7.9159e-01, 4.4324e-01, 7.8603e-01],\n",
      "         [3.7914e-01, 6.4498e-01, 2.1518e-01, 3.9219e-01, 2.4353e-01],\n",
      "         ...,\n",
      "         [7.1501e-01, 2.6440e-01, 6.9092e-01, 2.2420e-01, 4.1338e-01],\n",
      "         [1.2211e-01, 4.9400e-01, 1.6430e-01, 5.3761e-01, 1.6422e-01],\n",
      "         [8.4791e-01, 7.2648e-01, 5.2821e-01, 8.9635e-01, 5.8703e-02]]])\n"
     ]
    }
   ],
   "source": [
    "print(special_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd165f58",
   "metadata": {},
   "source": [
    "### Zeroes and Ones \n",
    "\n",
    "Sometimes we may just want to fill tensors with zeroes and ones. This typically happens a lot with masking (like masking some of the values in one tensor with zeroes to let a model know not to learn them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10217164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f141b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5461e3bb",
   "metadata": {},
   "source": [
    "### Creating a range of Tensors and Tensors-like\n",
    "\n",
    "Sometimes you might want a range of numbers, such as 1 to 10 or 0 to 100. \n",
    "You can use `torch.arange(start, end, step)` to do so. \n",
    "\n",
    "Where: \n",
    "* start = start of range \n",
    "* end = end of range \n",
    "* step = how many steps in between each value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba574239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a range of values 0 to 10\n",
    "zero_to_ten = torch.arange(start=0, end=11, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a0db7f",
   "metadata": {},
   "source": [
    "Sometimes you might want a tensor of a certain type with the same shape as another tensor. For example, a tensor of all zeros with the same shape as a previous tensor. \n",
    "\n",
    "To do so you can use `torch.zeros_like(inpyt)` or `torch.ones_like(input)` which return a tensor filled with zeros or ones in the same shape as the input respectively. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1de33c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also create a tensor of zeros similar to another tensor\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten) # will have same shape\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a50f6924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11])\n",
      "torch.Size([11])\n"
     ]
    }
   ],
   "source": [
    "print(zero_to_ten.shape)\n",
    "print(ten_zeros.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4caca70",
   "metadata": {},
   "source": [
    "### Tensor Datatypes\n",
    "\n",
    "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch and Deep Learning:\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33545f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                                            # What datatype is the tensor (e.g. float32, float16, etc.)\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                                            # What device is the tensor on (e.g. CPU, GPU)\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "                                                    # Whether or not to track gradients with the tensor operations\n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fabd4c4",
   "metadata": {},
   "source": [
    "See the [PyTorch documentation for a list of all available tensor datatypes](https://pytorch.org/docs/stable/tensors.html#data-types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ztm-pytorch-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
